{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating generation quality performance metrics of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Azure OpenAI service connection\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI Connection\n",
    "model_config = {\n",
    "        \"azure_deployment\": \"gpt-4\",\n",
    "        \"api_version\": os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        \"azure_endpoint\": os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create the website copy for the tents catalog ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create the textual assets for the sleeping bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Draft the website copy for the hiking shoes we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  Create the website copy for the tents catalog ...\n",
       "1  Create the textual assets for the sleeping bag...\n",
       "2  Draft the website copy for the hiking shoes we..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploading test dataset\n",
    "import pandas as pd\n",
    "\n",
    "test_data_path = \"../data/test_dataset.jsonl\"\n",
    "\n",
    "df = pd.read_json(test_data_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing class evaluators \n",
    "from create_website_copy_request import get_response\n",
    "from azure.ai.evaluation import RelevanceEvaluator, GroundednessEvaluator, FluencyEvaluator, CoherenceEvaluator, evaluate\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241011130828_chat_evaluation_sdk\n"
     ]
    }
   ],
   "source": [
    "# Create unique id for each run with date and time\n",
    "from datetime import datetime\n",
    "run_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run_id = f\"{run_id}_chat_evaluation_sdk\"    \n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "resource_group_name= os.environ[\"AZURE_RESOURCE_GROUP\"]\n",
    "project_name = os.environ[\"AZURE_AI_PROJECT_NAME\"]\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": subscription_id,\n",
    "    \"resource_group_name\": resource_group_name,\n",
    "    \"project_name\": project_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_response_data(df):\n",
    "    results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        \n",
    "        # Run get response\n",
    "        response = get_response(question)\n",
    "                \n",
    "        # Add results to list\n",
    "        result = {\n",
    "            'query': question,\n",
    "            'context': response[\"context\"],\n",
    "            'response': response[\"answer\"]\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Save results to a JSONL file\n",
    "    with open('run_results.jsonl', 'w') as file:\n",
    "        for result in results:\n",
    "            file.write(json.dumps(result) + '\\n')\n",
    "    return results\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run web_designer_app against test dataset\n",
    "# Step 2: Evaluate outputs (answer and context) against generation quality metrics\n",
    "response_results = create_response_data(df)\n",
    "result_eval = evaluate(\n",
    "    evaluation_name=run_id,\n",
    "    data=\"run_results.jsonl\",\n",
    "    evaluators={\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "    },\n",
    "    # column mapping    \n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"query\": \"${data.query}\",\n",
    "            \"response\": \"${data.response}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project = azure_ai_project, # comment this line if you don't want to push results to your Azure AI Project\n",
    "    output_path=\"./eval_results.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Summarized Metrics-----\n",
      "{'relevance.gpt_relevance': 5.0, 'fluency.gpt_fluency': 5.0, 'coherence.gpt_coherence': 4.666666666666667, 'groundedness.gpt_groundedness': 5.0}\n",
      "-----Tabular Result-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.response</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create the website copy for the tents catalog ...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td># Explore Our Premium Tents Collection\\n\\nWelc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create the textual assets for the sleeping bag...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td>### CozyNights Sleeping Bag\\n\\n#### Price: $10...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Draft the website copy for the hiking shoes we...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td># TrailWalker Hiking Shoes by CONTOSO\\n\\n## Di...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inputs.query  \\\n",
       "0  Create the website copy for the tents catalog ...   \n",
       "1  Create the textual assets for the sleeping bag...   \n",
       "2  Draft the website copy for the hiking shoes we...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  ## Task\\nYou serve as a web copywriter for the...   \n",
       "1  ## Task\\nYou serve as a web copywriter for the...   \n",
       "2  ## Task\\nYou serve as a web copywriter for the...   \n",
       "\n",
       "                                     inputs.response  \\\n",
       "0  # Explore Our Premium Tents Collection\\n\\nWelc...   \n",
       "1  ### CozyNights Sleeping Bag\\n\\n#### Price: $10...   \n",
       "2  # TrailWalker Hiking Shoes by CONTOSO\\n\\n## Di...   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  outputs.fluency.gpt_fluency  \\\n",
       "0                                5                            5   \n",
       "1                                5                            5   \n",
       "2                                5                            5   \n",
       "\n",
       "   outputs.coherence.gpt_coherence  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                5                                      5   \n",
       "1                                4                                      5   \n",
       "2                                5                                      5   \n",
       "\n",
       "   line_number  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = pd.DataFrame(result_eval[\"rows\"])\n",
    "print(\"-----Summarized Metrics-----\")\n",
    "print(result_eval[\"metrics\"])\n",
    "print(\"-----Tabular Result-----\")\n",
    "eval_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the link to visualize eval results to Azure AI Studio\n",
    "result_eval[\"studio_url\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
